{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8931f9",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.threshold = threshold\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, criteria = 'gini', max_depth=10, min_samples=1):\n",
    "        self.criteria = criteria\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_tree(X, y)\n",
    "        return self\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_classes = len(np.unique(y))\n",
    "\n",
    "        if (depth >= self.max_depth) or (num_classes == 1) or (num_samples < self.min_samples):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value = leaf_value)\n",
    "\n",
    "        best_feature, best_threshold = self.best_split(X, y)\n",
    "\n",
    "        if best_feature is None:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value = leaf_value)\n",
    "\n",
    "        X_l, y_l, X_r, y_r = self.split_data(X, y, best_feature, best_threshold)\n",
    "\n",
    "        # Recursively build left and right subtrees\n",
    "        left_child = self.build_tree(X_l, y_l, depth + 1)\n",
    "        right_child = self.build_tree(X_r, y_r, depth + 1)\n",
    "\n",
    "        return Node(feature=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_feature = None\n",
    "        best_gain = -1\n",
    "        best_threshold = None\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        for feature_index in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                X_l, y_l, X_r, y_r = self.split_data(X, y, feature_index, threshold)\n",
    "                \n",
    "                if np.sum(y_l) == 0 or np.sum(y_r) == 0:\n",
    "                    continue\n",
    "\n",
    "                if self.information_gain(y, y_l, y_r) > best_gain:\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "    \n",
    "    def information_gain(self, parent, left_child, right_child):\n",
    "        n = len(parent)\n",
    "        n_left = len(left_child)\n",
    "        n_right = len(right_child)\n",
    "        if (n_left == 0) or (n_right) == 0:\n",
    "            return 0\n",
    "\n",
    "        parent_impurity = self.impurity(parent)\n",
    "        child_impurity = (n_left / n) * self.impurity(left_child) + (n_right / n) * self.impurity(right_child)\n",
    "        return parent_impurity - child_impurity\n",
    "\n",
    "    def impurity(self, y):\n",
    "        if self.criteria == 'gini':\n",
    "            return self.gini_value(y)\n",
    "        elif self.criteria == 'entropy':\n",
    "            return self.entropy(y)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def gini_value(self, y):\n",
    "        _, counts = np.unique(y, return_counts = True)\n",
    "        probs = counts/np.sum(counts)\n",
    "        return 1 - np.sum(probs ** 2)\n",
    "\n",
    "    def entropy(self, y):\n",
    "        _, counts = np.unique(y, return_counts = True)\n",
    "        probs = counts/np.sum(counts)\n",
    "        return - np.sum(probs * np.log2(probs + 1e-9))\n",
    "\n",
    "    def split_data(self, X, y, feature_index, threshold):\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        right_mask = X[:, feature_index] > threshold\n",
    "        return X[left_mask], y[left_mask], X[right_mask], y[right_mask]\n",
    "\n",
    "    \n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        return counter.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self.traverse_tree(x, node.right)\n",
    "\n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        \"\"\"Print a text representation of the tree.\"\"\"\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        \n",
    "        if node.value is not None:\n",
    "            print(f\"{'  ' * depth}Leaf: class={node.value}\")\n",
    "        else:\n",
    "            print(f\"{'  ' * depth}Feature {node.feature} <= {node.threshold:.3f}\")\n",
    "            print(f\"{'  ' * depth}Left:\")\n",
    "            self.print_tree(node.left, depth + 1)\n",
    "            print(f\"{'  ' * depth}Right:\")\n",
    "            self.print_tree(node.right, depth + 1)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0ed8370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Decision Tree from Scratch - Example Usage\n",
      "============================================================\n",
      "\n",
      "1. Testing on Iris Dataset\n",
      "------------------------------------------------------------\n",
      "Accuracy (Gini): 0.5333\n",
      "Accuracy (Entropy): 0.5333\n",
      "\n",
      "2. Testing on Simple Custom Dataset\n",
      "------------------------------------------------------------\n",
      "\n",
      "Tree Structure:\n",
      "Feature 1 <= 6.000\n",
      "Left:\n",
      "  Feature 1 <= 5.000\n",
      "  Left:\n",
      "    Leaf: class=0\n",
      "  Right:\n",
      "    Leaf: class=1\n",
      "Right:\n",
      "  Leaf: class=1\n",
      "\n",
      "Predictions:\n",
      "Sample [1.5 2.5] -> Class 0\n",
      "Sample [5.5 6.5] -> Class 1\n",
      "\n",
      "3. Testing on Synthetic Dataset\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.5000\n",
      "Training samples: 400\n",
      "Test samples: 100\n",
      "\n",
      "============================================================\n",
      "All tests completed successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Decision Tree from Scratch - Example Usage\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example 1: Iris dataset\n",
    "print(\"\\n1. Testing on Iris Dataset\")\n",
    "print(\"-\" * 60)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train with Gini criterion\n",
    "dt_gini = DecisionTree(max_depth=5, criteria='gini')\n",
    "dt_gini.fit(X_train, y_train)\n",
    "y_pred_gini = dt_gini.predict(X_test)\n",
    "accuracy_gini = accuracy_score(y_test, y_pred_gini)\n",
    "print(f\"Accuracy (Gini): {accuracy_gini:.4f}\")\n",
    "\n",
    "# Train with Entropy criterion\n",
    "dt_entropy = DecisionTree(max_depth=5, criteria='entropy')\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "y_pred_entropy = dt_entropy.predict(X_test)\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "print(f\"Accuracy (Entropy): {accuracy_entropy:.4f}\")\n",
    "\n",
    "# Example 2: Simple custom dataset\n",
    "print(\"\\n2. Testing on Simple Custom Dataset\")\n",
    "print(\"-\" * 60)\n",
    "X_simple = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
    "y_simple = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "dt_simple = DecisionTree(max_depth=3)\n",
    "dt_simple.fit(X_simple, y_simple)\n",
    "\n",
    "print(\"\\nTree Structure:\")\n",
    "dt_simple.print_tree()\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "test_samples = np.array([[1.5, 2.5], [5.5, 6.5]])\n",
    "predictions = dt_simple.predict(test_samples)\n",
    "for sample, pred in zip(test_samples, predictions):\n",
    "    print(f\"Sample {sample} -> Class {pred}\")\n",
    "\n",
    "# Example 3: Larger synthetic dataset\n",
    "print(\"\\n3. Testing on Synthetic Dataset\")\n",
    "print(\"-\" * 60)\n",
    "X_synthetic, y_synthetic = make_classification(\n",
    "    n_samples=500, n_features=10, n_informative=5, \n",
    "    n_redundant=2, random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_synthetic, y_synthetic, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "dt_synthetic = DecisionTree(max_depth=10, min_samples=5)\n",
    "dt_synthetic.fit(X_train, y_train)\n",
    "y_pred_synthetic = dt_synthetic.predict(X_test)\n",
    "accuracy_synthetic = accuracy_score(y_test, y_pred_synthetic)\n",
    "print(f\"Accuracy: {accuracy_synthetic:.4f}\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All tests completed successfully!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513f610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
