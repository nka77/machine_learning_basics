{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18108bf8",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Neural Networks from Scratch\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook walks through the implementation of a **feed-forward neural network (MLP)** using **only NumPy**.\n",
    "\n",
    "The purpose is to understand:\n",
    "\n",
    "* how neural networks compute outputs\n",
    "* how gradients are calculated via backpropagation\n",
    "* how learning happens through gradient descent\n",
    "\n",
    "In brief, we have\n",
    "* **Layer:** `Z = X @ W + b`, `A = f(Z)`\n",
    "* **Activation (ReLU):** `ReLU(z) = max(0, z)`\n",
    "* **Loss (MSE):** `L = mean((y - ŷ)²)`\n",
    "* **Backprop:**\n",
    "\n",
    "  ```\n",
    "  dW = Xᵀ @ dZ\n",
    "  db = sum(dZ)\n",
    "  dX = dZ @ Wᵀ\n",
    "  ```\n",
    "* **Update:** `W -= lr * dW`, `b -= lr * db`\n",
    "\n",
    "> Linear algebra + non-linearity + gradients = learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a32f4b",
   "metadata": {},
   "source": [
    "## Core Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b3697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8fb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activations\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2096a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss Functions\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mse_derivative(y_true, y_pred):\n",
    "    return -2 * (y_true - y_pred) / y_true.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15605ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fully Connected Layer or Dense Layer\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.w = np.random.randn(input_dim, output_dim) * 0.01\n",
    "        self.b = np.zeros((1, output_dim))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.Z = self.X @ self.w + self.b\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.01):\n",
    "        m = self.X.shape[0]\n",
    "        self.dw = self.X.T @ dZ / m\n",
    "        self.db = np.sum(dZ, axis=0, keepdims=True) / m\n",
    "        dX = dZ @ self.w.T\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.w -= learning_rate * self.dw\n",
    "        self.b -= learning_rate * self.db\n",
    "        \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "122c58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    def __init__(self, func, func_derivative):\n",
    "        self.func = func\n",
    "        self.func_derivative = func_derivative\n",
    "\n",
    "    def forward(self, Z):\n",
    "        self.Z = Z\n",
    "        return self.func(Z)\n",
    "\n",
    "    def backward(self, dA):\n",
    "        return dA * self.func_derivative(self.Z)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "\n",
    "    def backward(self, dLoss, lr):\n",
    "        for layer in reversed(self.layers):\n",
    "            dLoss = layer.backward(dLoss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2013ce",
   "metadata": {},
   "source": [
    "### Lets try it out!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82be98d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 12.4316\n",
      "Epoch 100, Loss: 11.9718\n",
      "Epoch 200, Loss: 11.5301\n",
      "Epoch 300, Loss: 11.1056\n",
      "Epoch 400, Loss: 10.6976\n",
      "Epoch 500, Loss: 10.3056\n",
      "Epoch 600, Loss: 9.9289\n",
      "Epoch 700, Loss: 9.5667\n",
      "Epoch 800, Loss: 9.2186\n",
      "Epoch 900, Loss: 8.8840\n"
     ]
    }
   ],
   "source": [
    "# Dummy dataset\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 1)\n",
    "y = 3 * X + 2\n",
    "\n",
    "# Build network\n",
    "nn = NeuralNetwork()\n",
    "nn.add(DenseLayer(1, 16))\n",
    "nn.add(Activation(relu, relu_derivative))\n",
    "nn.add(DenseLayer(16, 1))\n",
    "\n",
    "# Train\n",
    "epochs = 1000\n",
    "lr = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_pred = nn.forward(X)\n",
    "    loss = mse(y, y_pred)\n",
    "\n",
    "    dLoss = mse_derivative(y, y_pred)\n",
    "    nn.backward(dLoss, lr)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e7ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
